{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Parallelism with Machine Learning: The Housing Prices Competition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the competition\n",
    "\n",
    "- The Housing Prices Competition train_dataset consists of various features of residential homes in Ames, Iowa, including both quantitative and categorical variables like the size of the property, the number of rooms, year built, and neighborhood quality.\n",
    "- It includes a set of 79 explanatory variables describing almost every aspect of the houses, allowing for in-depth analysis.\n",
    "- *The primary goal* of the competition is to predict **the final price of each home**, in this lab we will use *RandomForests*.\n",
    "- The models are evaluated on Root Mean Squared Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price, encouraging precise predictions over a range of housing prices.\n",
    "\n",
    "### File descriptions\n",
    "- *train.csv*: the training set used to train the model.\n",
    "- *test.csv*: the test set used to compute the performance of the model.\n",
    "- *train_data_description.txt*: full description of each column.\n",
    "### Useful train_data fields\n",
    "\n",
    "Here's a brief version of what you'll find in the train_data description file.\n",
    "\n",
    "- *SalePrice*: the property's sale price in dollars. This is the target variable that you're trying to predict.\n",
    "- *MSSubClass*: The building class\n",
    "- *MSZoning*: The general zoning classification\n",
    "\n",
    "Teh train_dataset is acessible here: https://www.kaggle.com/code/dansbecker/random-forests/tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and prepare the train_data\n",
    "*If you're curious about this the professor can explain it for you*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MSSubClass  MSZoning  LotFrontage  LotArea  Street  LotShape  LandContour  \\\n",
      "Id                                                                              \n",
      "1           60         3         65.0     8450       1         3            3   \n",
      "2           20         3         80.0     9600       1         3            3   \n",
      "3           60         3         68.0    11250       1         0            3   \n",
      "4           70         3         60.0     9550       1         0            3   \n",
      "5           60         3         84.0    14260       1         0            3   \n",
      "\n",
      "    Utilities  LotConfig  LandSlope  ...  GarageQual  GarageCond  PavedDrive  \\\n",
      "Id                                   ...                                       \n",
      "1           0          4          0  ...           4           4           2   \n",
      "2           0          2          0  ...           4           4           2   \n",
      "3           0          4          0  ...           4           4           2   \n",
      "4           0          0          0  ...           4           4           2   \n",
      "5           0          2          0  ...           4           4           2   \n",
      "\n",
      "    WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  \\\n",
      "Id                                                                             \n",
      "1            0           61              0          0            0         0   \n",
      "2          298            0              0          0            0         0   \n",
      "3            0           42              0          0            0         0   \n",
      "4            0           35            272          0            0         0   \n",
      "5          192           84              0          0            0         0   \n",
      "\n",
      "    MiscVal  \n",
      "Id           \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "5         0  \n",
      "\n",
      "[5 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the train_dataset\n",
    "file_path = 'data/housing_prices_data/train.csv'\n",
    "train_data = pd.read_csv(file_path, index_col=\"Id\")\n",
    "\n",
    "# Columns to be deleted\n",
    "columns_to_delete = ['MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "\n",
    "# Delete the specified columns\n",
    "train_data_cleaned = train_data.drop(columns=columns_to_delete, axis=1)\n",
    "\n",
    "# Define the input features (X) and the output (y)\n",
    "X = train_data_cleaned.drop('SalePrice', axis=1)\n",
    "y = train_data_cleaned['SalePrice']\n",
    "\n",
    "# Identify the categorical columns in X\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Initialize a LabelEncoder for each categorical column\n",
    "label_encoders = {column: LabelEncoder() for column in categorical_columns}\n",
    "\n",
    "# Apply Label Encoding to each categorical column\n",
    "for column in categorical_columns:\n",
    "    X[column] = label_encoders[column].fit_transform(X[column])\n",
    "\n",
    "# Display the first few rows of X to confirm the encoding\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 70), (438, 70), (1022,), (438,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the first dataset (X, y) into train and test sets with a 70% - 30% split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Fill NaN values in X_train and X_val with the median of the respective columns\n",
    "X_train_filled = X_train.fillna(X_train.median())\n",
    "X_val_filled = X_val.fillna(X_val.median())\n",
    "\n",
    "(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First RandomForest Model\n",
    "This is the code for a simple trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the validation data: 26057.941851126383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Create a Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_model.fit(X_train_filled, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_val_pred_filled = rf_model.predict(X_val_filled)\n",
    "\n",
    "# Calculate the RMSE on the validation data\n",
    "rmse_filled = sqrt(mean_squared_error(y_val, y_val_pred_filled))\n",
    "\n",
    "# Print the RMSE\n",
    "print(f'RMSE on the validation data: {rmse_filled}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of Random Forest Model\n",
    "The three most important parameters that typically have the most impact on the performance of a Random Forest model are:\n",
    "\n",
    "- *n_estimators*: This parameter specifies the number of trees in the forest. Generally, a higher number of trees increases the performance and makes the predictions more stable, but it also makes the computation slower. Selecting the right number of trees requires balancing between performance and computational efficiency.\n",
    "\n",
    "- *max_features*: This parameter defines the maximum number of features that are allowed to try in an individual tree. There are several options available for this parameter:\n",
    "\n",
    "    - *sqrt*: This is commonly used and means that the maximum number of features used at each split is the square root of the total number of features.\n",
    "    - *log2*: This is another typical option, meaning the log base 2 of the feature count is used.\n",
    "    - *A specific integer or float*: You can specify an exact number or a proportion of the total.\n",
    "\n",
    "- *max_depth*: This parameter specifies the maximum depth of each tree. Deeper trees can model more complex patterns, but they also risk overfitting. Limiting the depth of trees can improve the model's generalization and reduce overfitting. It's often useful to set this parameter to a finite value, especially when dealing with a large number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best parameters sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters: 10, sqrt, 1. RMSE: 62936.129262244904, MAPE: 26.860734529882123%\n",
      "The parameters: 10, sqrt, 2. RMSE: 51806.105176310826, MAPE: 20.52147680573829%\n",
      "The parameters: 10, sqrt, 5. RMSE: 34018.6946431472, MAPE: 13.846204059816515%\n",
      "The parameters: 10, sqrt, 10. RMSE: 30158.362616471855, MAPE: 11.1847373574493%\n",
      "The parameters: 10, sqrt, 20. RMSE: 30593.76147467334, MAPE: 11.148658516638926%\n",
      "The parameters: 10, sqrt, None. RMSE: 28608.440009540453, MAPE: 11.124252485645316%\n",
      "The parameters: 10, log2, 1. RMSE: 64442.107292878405, MAPE: 27.58882909655716%\n",
      "The parameters: 10, log2, 2. RMSE: 51396.530250771764, MAPE: 21.498982900746558%\n",
      "The parameters: 10, log2, 5. RMSE: 34956.394381827566, MAPE: 13.945831547616713%\n",
      "The parameters: 10, log2, 10. RMSE: 30136.927641357106, MAPE: 11.160840785213171%\n",
      "The parameters: 10, log2, 20. RMSE: 30841.310557247474, MAPE: 11.240205002153882%\n",
      "The parameters: 10, log2, None. RMSE: 29000.351214559596, MAPE: 10.98098439114081%\n",
      "The parameters: 10, None, 1. RMSE: 57823.30960766656, MAPE: 25.854236053260713%\n",
      "The parameters: 10, None, 2. RMSE: 44738.9675013081, MAPE: 19.39967435427367%\n",
      "The parameters: 10, None, 5. RMSE: 30977.339419939668, MAPE: 12.32718845204275%\n",
      "The parameters: 10, None, 10. RMSE: 26371.732325187742, MAPE: 10.387601696539232%\n",
      "The parameters: 10, None, 20. RMSE: 27582.089072839033, MAPE: 10.336644923118392%\n",
      "The parameters: 10, None, None. RMSE: 28062.104755431203, MAPE: 10.28772353916743%\n",
      "The parameters: 25, sqrt, 1. RMSE: 60720.06723428002, MAPE: 25.2463033064465%\n",
      "The parameters: 25, sqrt, 2. RMSE: 48999.969822412146, MAPE: 19.141115612087532%\n",
      "The parameters: 25, sqrt, 5. RMSE: 32317.961786662752, MAPE: 13.114437916762203%\n",
      "The parameters: 25, sqrt, 10. RMSE: 28259.543521821943, MAPE: 10.47369873275887%\n",
      "The parameters: 25, sqrt, 20. RMSE: 28601.996953881055, MAPE: 10.651671775420226%\n",
      "The parameters: 25, sqrt, None. RMSE: 28437.477716170713, MAPE: 10.650717147533856%\n",
      "The parameters: 25, log2, 1. RMSE: 62175.23336548907, MAPE: 26.103334605968907%\n",
      "The parameters: 25, log2, 2. RMSE: 49454.96222058965, MAPE: 20.009887677109557%\n",
      "The parameters: 25, log2, 5. RMSE: 34640.741335575985, MAPE: 13.585957690083541%\n",
      "The parameters: 25, log2, 10. RMSE: 29797.647023472127, MAPE: 10.802129162615948%\n",
      "The parameters: 25, log2, 20. RMSE: 28152.423144151206, MAPE: 10.113221227840645%\n",
      "The parameters: 25, log2, None. RMSE: 28624.714349076796, MAPE: 10.195238945186857%\n",
      "The parameters: 25, None, 1. RMSE: 57545.23094798376, MAPE: 25.562043938945223%\n",
      "The parameters: 25, None, 2. RMSE: 44503.99568777034, MAPE: 18.93356623365525%\n",
      "The parameters: 25, None, 5. RMSE: 30622.018751108048, MAPE: 12.284801453967585%\n",
      "The parameters: 25, None, 10. RMSE: 27253.405412634103, MAPE: 10.272632581222856%\n",
      "The parameters: 25, None, 20. RMSE: 26499.315199813544, MAPE: 10.019023380641842%\n",
      "The parameters: 25, None, None. RMSE: 27011.528848190042, MAPE: 10.057567711051357%\n",
      "The parameters: 50, sqrt, 1. RMSE: 60346.5737195233, MAPE: 25.162121091064353%\n",
      "The parameters: 50, sqrt, 2. RMSE: 48952.98192411672, MAPE: 19.219570888426375%\n",
      "The parameters: 50, sqrt, 5. RMSE: 32807.733869677046, MAPE: 12.765423020132053%\n",
      "The parameters: 50, sqrt, 10. RMSE: 28193.908384996157, MAPE: 10.30283712157863%\n",
      "The parameters: 50, sqrt, 20. RMSE: 28322.13190140527, MAPE: 10.266831234466041%\n",
      "The parameters: 50, sqrt, None. RMSE: 28253.30753002766, MAPE: 10.301610941463089%\n",
      "The parameters: 50, log2, 1. RMSE: 61769.11746990103, MAPE: 26.024888854218215%\n",
      "The parameters: 50, log2, 2. RMSE: 49973.37697266408, MAPE: 19.855069340876533%\n",
      "The parameters: 50, log2, 5. RMSE: 35272.23782970266, MAPE: 13.259237055635129%\n",
      "The parameters: 50, log2, 10. RMSE: 29337.548793235695, MAPE: 10.69972715022594%\n",
      "The parameters: 50, log2, 20. RMSE: 28219.379219234233, MAPE: 10.054841695082303%\n",
      "The parameters: 50, log2, None. RMSE: 28552.120501147994, MAPE: 10.110335561128336%\n",
      "The parameters: 50, None, 1. RMSE: 57505.08832414332, MAPE: 25.40677081979206%\n",
      "The parameters: 50, None, 2. RMSE: 44571.23631103615, MAPE: 18.993732376822592%\n",
      "The parameters: 50, None, 5. RMSE: 30578.268789069476, MAPE: 12.246352597445519%\n",
      "The parameters: 50, None, 10. RMSE: 26549.03681495154, MAPE: 10.164540522209597%\n",
      "The parameters: 50, None, 20. RMSE: 26616.753965688236, MAPE: 9.95616179407857%\n",
      "The parameters: 50, None, None. RMSE: 26659.206888314602, MAPE: 9.950072723845874%\n",
      "The parameters: 100, sqrt, 1. RMSE: 60511.413390408285, MAPE: 24.970655834062548%\n",
      "The parameters: 100, sqrt, 2. RMSE: 48423.20979308409, MAPE: 19.124218836706603%\n",
      "The parameters: 100, sqrt, 5. RMSE: 32585.44117019146, MAPE: 12.510275320688514%\n",
      "The parameters: 100, sqrt, 10. RMSE: 27940.66308571875, MAPE: 10.232467246501514%\n",
      "The parameters: 100, sqrt, 20. RMSE: 27530.724415300712, MAPE: 10.125866760621907%\n",
      "The parameters: 100, sqrt, None. RMSE: 27690.85111196373, MAPE: 10.111048513592108%\n",
      "The parameters: 100, log2, 1. RMSE: 62166.92632864128, MAPE: 25.90574767935297%\n",
      "The parameters: 100, log2, 2. RMSE: 49946.811096505524, MAPE: 19.85047840173841%\n",
      "The parameters: 100, log2, 5. RMSE: 34438.66151846642, MAPE: 13.17388786526951%\n",
      "The parameters: 100, log2, 10. RMSE: 28459.288873741767, MAPE: 10.547559689956204%\n",
      "The parameters: 100, log2, 20. RMSE: 27471.51821338425, MAPE: 9.805906069975684%\n",
      "The parameters: 100, log2, None. RMSE: 27735.747830866087, MAPE: 10.003262143296658%\n",
      "The parameters: 100, None, 1. RMSE: 57211.16615127391, MAPE: 25.025965875120264%\n",
      "The parameters: 100, None, 2. RMSE: 44472.47296968139, MAPE: 18.836095197090465%\n",
      "The parameters: 100, None, 5. RMSE: 30154.47423520161, MAPE: 12.085654020145233%\n",
      "The parameters: 100, None, 10. RMSE: 26265.099994067186, MAPE: 10.040721857978957%\n",
      "The parameters: 100, None, 20. RMSE: 26152.741599610163, MAPE: 9.913529753089874%\n",
      "The parameters: 100, None, None. RMSE: 26057.941851126383, MAPE: 9.868196740754167%\n",
      "The parameters: 200, sqrt, 1. RMSE: 60592.20080413971, MAPE: 25.348413331204604%\n",
      "The parameters: 200, sqrt, 2. RMSE: 48456.200987649645, MAPE: 19.31834333556386%\n",
      "The parameters: 200, sqrt, 5. RMSE: 32921.85786148226, MAPE: 12.593595077314337%\n",
      "The parameters: 200, sqrt, 10. RMSE: 28088.902620554447, MAPE: 10.205458456989026%\n",
      "The parameters: 200, sqrt, 20. RMSE: 27532.91156851607, MAPE: 9.99674498484024%\n",
      "The parameters: 200, sqrt, None. RMSE: 27430.923405573616, MAPE: 10.001128964051244%\n",
      "The parameters: 200, log2, 1. RMSE: 62120.39237086007, MAPE: 26.338849401949805%\n",
      "The parameters: 200, log2, 2. RMSE: 50047.12857344109, MAPE: 20.132262501400174%\n",
      "The parameters: 200, log2, 5. RMSE: 34734.445288631454, MAPE: 13.310668983679474%\n",
      "The parameters: 200, log2, 10. RMSE: 28692.19328330196, MAPE: 10.425408664401772%\n",
      "The parameters: 200, log2, 20. RMSE: 27918.172300177175, MAPE: 9.871948875899832%\n",
      "The parameters: 200, log2, None. RMSE: 28122.610919892722, MAPE: 10.075865891296619%\n",
      "The parameters: 200, None, 1. RMSE: 57330.65911329287, MAPE: 25.203756111774418%\n",
      "The parameters: 200, None, 2. RMSE: 44545.47770035227, MAPE: 18.8459387073764%\n",
      "The parameters: 200, None, 5. RMSE: 30056.99415042013, MAPE: 12.027413013145498%\n",
      "The parameters: 200, None, 10. RMSE: 26485.54967760915, MAPE: 9.968649121179467%\n",
      "The parameters: 200, None, 20. RMSE: 26191.615393143096, MAPE: 9.814804116215956%\n",
      "The parameters: 200, None, None. RMSE: 26109.529848542985, MAPE: 9.785264413857124%\n",
      "The parameters: 300, sqrt, 1. RMSE: 60929.66932059552, MAPE: 25.5233017132497%\n",
      "The parameters: 300, sqrt, 2. RMSE: 48477.515732693806, MAPE: 19.45952457308847%\n",
      "The parameters: 300, sqrt, 5. RMSE: 32739.920144412845, MAPE: 12.654260849343446%\n",
      "The parameters: 300, sqrt, 10. RMSE: 27720.206311955073, MAPE: 10.158753220059861%\n",
      "The parameters: 300, sqrt, 20. RMSE: 27459.785134152986, MAPE: 9.886952721263405%\n",
      "The parameters: 300, sqrt, None. RMSE: 27394.84596466395, MAPE: 9.923924926914179%\n",
      "The parameters: 300, log2, 1. RMSE: 62683.20415726862, MAPE: 26.538128720991566%\n",
      "The parameters: 300, log2, 2. RMSE: 50458.67950947336, MAPE: 20.275483738507045%\n",
      "The parameters: 300, log2, 5. RMSE: 34565.6574161325, MAPE: 13.300516763849002%\n",
      "The parameters: 300, log2, 10. RMSE: 28541.379624482677, MAPE: 10.42483342213683%\n",
      "The parameters: 300, log2, 20. RMSE: 27744.585234343336, MAPE: 9.924986717080374%\n",
      "The parameters: 300, log2, None. RMSE: 27972.716859688764, MAPE: 10.050994009021618%\n",
      "The parameters: 300, None, 1. RMSE: 57645.45868384868, MAPE: 25.615849754017994%\n",
      "The parameters: 300, None, 2. RMSE: 44468.13497206259, MAPE: 18.973613128632305%\n",
      "The parameters: 300, None, 5. RMSE: 30053.282347030145, MAPE: 12.040192412613166%\n",
      "The parameters: 300, None, 10. RMSE: 26435.067646149004, MAPE: 9.957708448691804%\n",
      "The parameters: 300, None, 20. RMSE: 26224.452972222785, MAPE: 9.831241564947488%\n",
      "The parameters: 300, None, None. RMSE: 26176.10432944751, MAPE: 9.801826393115594%\n",
      "The parameters: 400, sqrt, 1. RMSE: 60914.53857642404, MAPE: 25.51869058914844%\n",
      "The parameters: 400, sqrt, 2. RMSE: 48669.695843852176, MAPE: 19.530745286106946%\n",
      "The parameters: 400, sqrt, 5. RMSE: 32809.62783027221, MAPE: 12.71009467191943%\n",
      "The parameters: 400, sqrt, 10. RMSE: 27744.18030444477, MAPE: 10.125160913453673%\n",
      "The parameters: 400, sqrt, 20. RMSE: 27497.671359831445, MAPE: 9.905124417060355%\n",
      "The parameters: 400, sqrt, None. RMSE: 27418.113736521427, MAPE: 9.945984648595795%\n",
      "The parameters: 400, log2, 1. RMSE: 62661.54638863782, MAPE: 26.43424504101804%\n",
      "The parameters: 400, log2, 2. RMSE: 50422.97022602301, MAPE: 20.23343384859187%\n",
      "The parameters: 400, log2, 5. RMSE: 34496.868353168815, MAPE: 13.290480205939964%\n",
      "The parameters: 400, log2, 10. RMSE: 28518.64779526882, MAPE: 10.390264584164836%\n",
      "The parameters: 400, log2, 20. RMSE: 27800.35162861101, MAPE: 9.91776916154931%\n",
      "The parameters: 400, log2, None. RMSE: 27905.32754903062, MAPE: 10.017981777351737%\n",
      "The parameters: 400, None, 1. RMSE: 57795.7474853705, MAPE: 25.753019610226186%\n",
      "The parameters: 400, None, 2. RMSE: 44508.690046548625, MAPE: 19.00415009775348%\n",
      "The parameters: 400, None, 5. RMSE: 30246.733688359316, MAPE: 12.052665031964972%\n",
      "The parameters: 400, None, 10. RMSE: 26626.130211240506, MAPE: 9.967897691949654%\n",
      "The parameters: 400, None, 20. RMSE: 26466.61626732859, MAPE: 9.851633812842412%\n",
      "The parameters: 400, None, None. RMSE: 26362.199455330487, MAPE: 9.83203095544113%\n",
      "The best parameters {'n_estimators': 100, 'max_features': None, 'max_depth': None} for RMSE = 26057.941851126383, MAPE: 9.83203095544113%\n",
      "The sequential execution time is 63.88221883773804\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the parameter ranges\n",
    "n_estimators_range = [10, 25, 50, 100, 200, 300, 400]\n",
    "max_features_range = ['sqrt', 'log2', None]  # None means using all features\n",
    "max_depth_range = [1, 2, 5, 10, 20, None]  # None means no limit\n",
    "\n",
    "# Initialize variables to store the best model and its RMSE and parameters\n",
    "best_rmse = float('inf')\n",
    "best_mape = float('inf')\n",
    "best_model = None\n",
    "best_parameters = {}\n",
    "\n",
    "# Loop over all possible combinations of parameters\n",
    "for n_estimators in n_estimators_range:\n",
    "    for max_features in max_features_range:\n",
    "        for max_depth in max_depth_range:\n",
    "            # Create and train the Random Forest model\n",
    "            rf_model = RandomForestRegressor(\n",
    "                n_estimators=n_estimators,\n",
    "                max_features=max_features,\n",
    "                max_depth=max_depth,\n",
    "                random_state=42\n",
    "            )\n",
    "            rf_model.fit(X_train_filled, y_train)\n",
    "            \n",
    "            # Make predictions and compute RMSE\n",
    "            y_val_pred = rf_model.predict(X_val_filled)\n",
    "            rmse = sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "            # Compute MAPE\n",
    "            mape = mean_absolute_percentage_error(y_val, y_val_pred) * 100\n",
    "            print(f\"The parameters: {n_estimators}, {max_features}, {max_depth}. RMSE: {rmse}, MAPE: {mape}%\")\n",
    "            # If the model is better than the current best, update the best model and its parameters\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_mape = mape\n",
    "                best_model = rf_model\n",
    "                best_parameters = {\n",
    "                    'n_estimators': n_estimators,\n",
    "                    'max_features': max_features,\n",
    "                    'max_depth': max_depth\n",
    "                }\n",
    "print(f\"The best parameters {best_parameters} for RMSE = {best_rmse}, MAPE: {mape}%\")\n",
    "end_time = time.time()\n",
    "sequential_time = start_time - end_time\n",
    "print(f\"The sequential execution time is {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
